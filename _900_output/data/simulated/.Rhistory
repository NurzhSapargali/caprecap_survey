# Since we have only 2 groups, Z is Bernoulli with probability p1
# Just need to shift those by +1 to so that Z in {1, 2}
z = rbinom(n, 1, p1) + 1
# Generate Y given Z
component_sample = function(z, mu1, mu2, sigma1, sigma2){
if (z == 1){
y = rnorm(1, mu1, sigma1)
} else {
y = rnorm(1, mu2, sigma2)
}
return(y)
}
# Apply function for each value of Z
y = sapply(z, function(x) { component_sample(x, mu1, mu2, sigma1, sigma2) })
# Visualize observed data y
hist(y)
# Function to evaluate posterior Z | Y = y (for a single y and z)
post_zy = function(z, y, mu1, mu2, sigma1, sigma2, p1){
# Numerator first
if (z == 1){
numr = dnorm(y, mu1, sigma1) * p1
} else {
numr = dnorm(y, mu2, sigma2) * (1.0 - p1)
}
# Divide numerator by the marginal, then output
numr / f_y(y, mu1, mu2, sigma1, sigma2, p1)
}
# Updating function for p1
update_p1 = function(y, mu1, mu2, sigma1, sigma2, p1){
# Posteriors at Z = 1 for each y
posts = sapply(y, function(x){ post_zy(1, x, mu1, mu2, sigma1, sigma2, p1) })
sum(posts) / length(y)
}
# Updating function for mu1
update_mu1 = function(y, mu1, mu2, sigma1, sigma2, p1){
# Posteriors at Z = 1 for each y
posts = sapply(y, function(x){ post_zy(1, x, mu1, mu2, sigma1, sigma2, p1) })
sum(posts * y) / sum(posts)
}
# Updating function for mu1
update_mu2 = function(y, mu1, mu2, sigma1, sigma2, p1){
# Posteriors at Z = 2 for each y
posts = sapply(y, function(x){ post_zy(2, x, mu1, mu2, sigma1, sigma2, p1) })
sum(posts * y) / sum(posts)
}
# Updating function for sigma1
update_sigma1 = function(y, mu1, mu2, sigma1, sigma2, p1, new_mu1){
# Posteriors at Z = 1 for each y
posts = sapply(y, function(x){ post_zy(1, x, mu1, mu2, sigma1, sigma2, p1) })
(sum(posts * (y - new_mu1)^2) / sum(posts))^0.5
}
# Updating function for sigma1
update_sigma2 = function(y, mu1, mu2, sigma1, sigma2, p1, new_mu2){
# Posteriors at Z = 2 for each y
posts = sapply(y, function(x){ post_zy(2, x, mu1, mu2, sigma1, sigma2, p1) })
(sum(posts * (y - new_mu2)^2) / sum(posts))^0.5
}
# Initial guess for each parameter
mu1_hat = 60
mu2_hat = 80
sigma1_hat = 2.5
sigma2_hat = 5
p1_hat = 0.2
# Iterate for 20 iterations
for (t in 1:20){
# Update
new_p1 = update_p1(y, mu1_hat, mu2_hat, sigma1_hat, sigma2_hat, p1_hat)
new_mu1 = update_mu1(y, mu1_hat, mu2_hat, sigma1_hat, sigma2_hat, p1_hat)
new_mu2 = update_mu2(y, mu1_hat, mu2_hat, sigma1_hat, sigma2_hat, p1_hat)
new_sigma1 = update_sigma1(y, mu1_hat, mu2_hat, sigma1_hat, sigma2_hat, p1_hat, new_mu1)
new_sigma2 = update_sigma2(y, mu1_hat, mu2_hat, sigma1_hat, sigma2_hat, p1_hat, new_mu2)
# Set to current
p1_hat = new_p1
mu1_hat = new_mu1
mu2_hat = new_mu2
sigma1_hat = new_sigma1
sigma2_hat = new_sigma2
}
cat(p1_hat, p1)
cat(mu1_hat, mu1)
cat(sigma1_hat, sigma1)
cat(mu2_hat, mu2)
cat(sigma2_hat, sigma2)
# Create table with true labels and observed data
dat = data.frame(y = y, z = z)
# Label prediction function: choose the one with the highest posterior probability
predict_z = function(y, mu1, mu2, sigma1, sigma2, p1){
prob_1 = post_zy(1, y, mu1, mu2, sigma1, sigma2, p1)
prob_2 = post_zy(2, y, mu1, mu2, sigma1, sigma2, p1)
if (prob_1 > prob_2){
z_hat = 1
} else {
z_hat = 2
}
return(z_hat)
}
# Predict labels for each y
dat$z_hat = sapply(dat$y, function(x){ predict_z(x, mu1_hat, mu2_hat, sigma1_hat, sigma2_hat, p1_hat) })
# Print accuracy rate
cat(sum(dat$z == dat$z_hat) / length(dat$y))
# Convert to factor (categorical variable basically) for visualisation
dat$z_hat = as.factor(dat$z_hat)
# Plot again the true density for observed points
dat$dens = f_y(dat$y, mu1, mu2, sigma1, sigma2, p1)
# Add individual component densities scaled by their weights
dat$comp1 = dnorm(dat$y, mu1, sigma1) * p1
dat$comp2 = dnorm(dat$y, mu2, sigma2) * p2
ggplot(data = dat, mapping = aes(x = y, y = dens)) +
geom_line() +
geom_line(mapping = aes(y = comp1), linetype = "dashed", alpha = 0.75, color = "red") +
geom_line(mapping = aes(y = comp2), linetype = "dashed", alpha = 0.75, color = "blue") +
geom_point(mapping = aes(y = 0, x = y, group = z_hat, color = z_hat), shape = 17, size = 1.5) +
theme_classic()
clear()
clean
clean()
library(ggplot2)
library(ggplot2)
set.seed(777) # Set random generator seed for reproducibility
p1 = 0.5 # Weight of the first component
mu1 = 55 # Mean of the first Gaussian
sigma1 = 6 # Standard deviation of the first Gaussian
# Parameters of the second component
p2 = 1.0 - p1
mu2 = 75
sigma2 = 12
# Density of Y (observed data)
f_y = function(y, mu1, mu2, sigma1, sigma2, p1){
p1 * dnorm(y, mu1, sigma1) + (1.0 - p1) * dnorm(y, mu2, sigma2)
}
# Plot density of Y in {20, 20.5, ..., 120}
dat = data.frame(y = seq(20, 120, 0.5))
dat$dens = f_y(dat$y, mu1, mu2, sigma1, sigma2, p1)
# Add individual component densities scaled by their weights
dat$comp1 = dnorm(dat$y, mu1, sigma1) * p1
dat$comp2 = dnorm(dat$y, mu2, sigma2) * p2
ggplot(data = dat, mapping = aes(x = y, y = dens)) +
geom_line() +
geom_line(mapping = aes(y = comp1), linetype = "dashed", alpha = 0.75, color = "red") +
geom_line(mapping = aes(y = comp2), linetype = "dashed", alpha = 0.75, color = "blue") +
theme_classic()
n = 1000 # Sample size
# Generate Z
# Since we have only 2 groups, Z is Bernoulli with probability p1
# Just need to shift those by +1 to so that Z in {1, 2}
z = rbinom(n, 1, p1) + 1
z
# Generate Y given Z
component_sample = function(z, mu1, mu2, sigma1, sigma2){
if (z == 1){
y = rnorm(1, mu1, sigma1)
} else {
y = rnorm(1, mu2, sigma2)
}
return(y)
}
# Apply function for each value of Z
y = sapply(z, function(x) { component_sample(x, mu1, mu2, sigma1, sigma2) })
# Visualize observed data y
hist(y)
# Function to evaluate posterior Z | Y = y (for a single y and z)
post_zy = function(z, y, mu1, mu2, sigma1, sigma2, p1){
# Numerator first
if (z == 1){
numr = dnorm(y, mu1, sigma1) * p1
} else {
numr = dnorm(y, mu2, sigma2) * (1.0 - p1)
}
# Divide numerator by the marginal, then output
numr / f_y(y, mu1, mu2, sigma1, sigma2, p1)
}
# Updating function for p1
update_p1 = function(y, mu1, mu2, sigma1, sigma2, p1){
# Posteriors at Z = 1 for each y
posts = sapply(y, function(x){ post_zy(1, x, mu1, mu2, sigma1, sigma2, p1) })
sum(posts) / length(y)
}
# Updating function for mu1
update_mu1 = function(y, mu1, mu2, sigma1, sigma2, p1){
# Posteriors at Z = 1 for each y
posts = sapply(y, function(x){ post_zy(1, x, mu1, mu2, sigma1, sigma2, p1) })
sum(posts * y) / sum(posts)
}
# Updating function for mu1
update_mu2 = function(y, mu1, mu2, sigma1, sigma2, p1){
# Posteriors at Z = 2 for each y
posts = sapply(y, function(x){ post_zy(2, x, mu1, mu2, sigma1, sigma2, p1) })
sum(posts * y) / sum(posts)
}
# Updating function for sigma1
update_sigma1 = function(y, mu1, mu2, sigma1, sigma2, p1, new_mu1){
# Posteriors at Z = 1 for each y
posts = sapply(y, function(x){ post_zy(1, x, mu1, mu2, sigma1, sigma2, p1) })
(sum(posts * (y - new_mu1)^2) / sum(posts))^0.5
}
# Updating function for sigma2
update_sigma2 = function(y, mu1, mu2, sigma1, sigma2, p1, new_mu2){
# Posteriors at Z = 2 for each y
posts = sapply(y, function(x){ post_zy(2, x, mu1, mu2, sigma1, sigma2, p1) })
(sum(posts * (y - new_mu2)^2) / sum(posts))^0.5
}
# Initial guess for each parameter
mu1_hat = 60
mu2_hat = 80
sigma1_hat = 2.5
sigma2_hat = 5
p1_hat = 0.2
# Iterate for 20 iterations
for (t in 1:20){
# Update
new_p1 = update_p1(y, mu1_hat, mu2_hat, sigma1_hat, sigma2_hat, p1_hat)
new_mu1 = update_mu1(y, mu1_hat, mu2_hat, sigma1_hat, sigma2_hat, p1_hat)
new_mu2 = update_mu2(y, mu1_hat, mu2_hat, sigma1_hat, sigma2_hat, p1_hat)
new_sigma1 = update_sigma1(y, mu1_hat, mu2_hat, sigma1_hat, sigma2_hat, p1_hat, new_mu1)
new_sigma2 = update_sigma2(y, mu1_hat, mu2_hat, sigma1_hat, sigma2_hat, p1_hat, new_mu2)
# Set to current
p1_hat = new_p1
mu1_hat = new_mu1
mu2_hat = new_mu2
sigma1_hat = new_sigma1
sigma2_hat = new_sigma2
}
cat(p1_hat, p1)
cat(mu1_hat, mu1)
cat(sigma1_hat, sigma1)
cat(mu2_hat, mu2)
cat(sigma2_hat, sigma2)
# Create table with true labels and observed data
dat = data.frame(y = y, z = z)
# Label prediction function: choose the one with the highest posterior probability
predict_z = function(y, mu1, mu2, sigma1, sigma2, p1){
prob_1 = post_zy(1, y, mu1, mu2, sigma1, sigma2, p1)
prob_2 = post_zy(2, y, mu1, mu2, sigma1, sigma2, p1)
if (prob_1 > prob_2){
z_hat = 1
} else {
z_hat = 2
}
return(z_hat)
}
# Predict labels for each y
dat$z_hat = sapply(dat$y, function(x){ predict_z(x, mu1_hat, mu2_hat, sigma1_hat, sigma2_hat, p1_hat) })
# Print accuracy rate
cat(sum(dat$z == dat$z_hat) / length(dat$y))
# Plot again the true density for observed points
dat$dens = f_y(dat$y, mu1, mu2, sigma1, sigma2, p1)
# Add individual component densities scaled by their weights
dat$comp1 = dnorm(dat$y, mu1, sigma1) * p1
dat$comp2 = dnorm(dat$y, mu2, sigma2) * p2
ggplot(data = dat, mapping = aes(x = y, y = dens)) +
geom_line() +
geom_line(mapping = aes(y = comp1), linetype = "dashed", alpha = 0.75, color = "red") +
geom_line(mapping = aes(y = comp2), linetype = "dashed", alpha = 0.75, color = "blue") +
geom_point(mapping = aes(y = 0, x = y, group = z_hat, color = z_hat), shape = 17, size = 1.5) +
theme_classic()
# Convert to factor (categorical variable basically) for visualisation
dat$z_hat = as.factor(dat$z_hat)
# Plot again the true density for observed points
dat$dens = f_y(dat$y, mu1, mu2, sigma1, sigma2, p1)
# Add individual component densities scaled by their weights
dat$comp1 = dnorm(dat$y, mu1, sigma1) * p1
dat$comp2 = dnorm(dat$y, mu2, sigma2) * p2
ggplot(data = dat, mapping = aes(x = y, y = dens)) +
geom_line() +
geom_line(mapping = aes(y = comp1), linetype = "dashed", alpha = 0.75, color = "red") +
geom_line(mapping = aes(y = comp2), linetype = "dashed", alpha = 0.75, color = "blue") +
geom_point(mapping = aes(y = 0, x = y, group = z_hat, color = z_hat), shape = 17, size = 1.5) +
theme_classic()
library(ggplot2)
x <- runif(1000)
y <- x + rnorm(1000)
dat <- data.frame(x = x, y = y)
ggplot(data = dat, mapping = aes(x = x, y = y)) +
geom_point()
library(ggplot2)
x <- runif(1000)
y <- x + rnorm(1000)
dat <- data.frame(x = x, y = y)
ggplot(data = dat, mapping = aes(x = x, y = y)) +
geom_point() +
theme_classic()
ggplot(data = dat, mapping = aes(x = x, y = y)) +
geom_point()
ggplot(data = dat, mapping = aes(x = x)) +
geom_histogram()
ggplot(data = dat, mapping = aes(x = x)) +
geom_density()
ggplot(data = dat, mapping = aes(x = x)) +
geom_density() +
geom_hist()
ggplot(data = dat, mapping = aes(x = x)) +
geom_density() +
geom_histogram()
ggplot(data = dat, mapping = aes(x = x)) +
geom_density() +
geom_histogram()
library(VGAM)
stat <- 11562.102671750246
n <- 10000
obj_f <- function(s){
-s * stat - n * log(zeta(s))
}
o <- optimise(obj_f, interval = c(1.01, 5))
library(VGAM)
stat <- 11562.102671750246
n <- 10000
obj_f <- function(s){
-s * stat - n * log(zeta(s))
}
o <- optimise(obj_f, interval = c(1.01, 5), maximum = TRUE)
o$maximum
c(rep(1, 903), rep(2, 71), rep(3, 20), rep(4, 2), rep(6, 3), rep(8, 1))
sum(log(c(rep(1, 903), rep(2, 71), rep(3, 20), rep(4, 2), rep(6, 3), rep(8, 1))))
length(log(c(rep(1, 903), rep(2, 71), rep(3, 20), rep(4, 2), rep(6, 3), rep(8, 1))))
library(VGAM)
stat <- 81.413
n <- 1000
obj_f <- function(s){
-s * stat - n * log(zeta(s))
}
o <- optimise(obj_f, interval = c(1.01, 5), maximum = TRUE)
o.x
o$maximum
o <- optimise(obj_f, interval = c(2, 6), maximum = TRUE)
o$maximum
devtools::load_all()
library(MASS) # High-dimensional kde
library(RColorBrewer)
rf <- colorRampPalette(rev(brewer.pal(11,'Spectral')))
r <- rf(32)
1 / 0.01
tau2 <- 0.01
mu <- 555
n <- 100
a <- 1.0
b <- 0.5
1 / 8
a <- 1.0
b <- 0.5
w2 <- 0.0001
1 / w2
y <- rnorm(n, mu, sd = sqrt(1.0 / tau2))
y
hist(y)
mcmc_iters <- 10000
mu_hat <- 0.0
mus <- c()
tau2s <- c()
for (i in 1:mcmc_iters) {
# Sample tau2
tau2_hat <- rgamma(
1,
shape = a + n / 2,
rate = b + 0.5 * sum((y - mu_hat)^2)
)
# Sample mu
mu_hat <- rnorm(
1,
mean = tau2_hat / (n * tau2_hat + w2) * sum(y),
sd = sqrt(1 / (n * tau2_hat + w2))
)
# Store samples
mus <- c(mus, mu_hat)
tau2s <- c(tau2s, tau2_hat)
}
plot(mus, type = "l", main = "Trace plot of mu", xlab = "Iteration", ylab = "mu")
mean(mus)
mu
hist(mus)
hist(mus[100:mcmc_iters])
plot(tau2s, type = "l", main = "Trace plot of tau2", xlab = "Iteration", ylab = "tau2")
dat <- data.frame(mu = mus, tau2 = tau2s)
dat <- dat[100:mcmc_iters, ] # Discard burn-in
h1 <- hist(dat$mu, plot=FALSE)
h2 <- hist(dat$tau2, plot=FALSE)
top <- max(h1$counts, h2$counts)
k <- kde2d(dat$mu, dat$tau2, n = 100)
# margins
oldpar <- par()
par(mar=c(3,3,1,1))
layout(matrix(c(2,0,1,3),2,2, byrow=TRUE),c(3,1), c(1,3))
image(k, col=r) #plot the image
par(mar=c(0,2,1,0))
barplot(h1$counts, axes=FALSE, space=0, col='red')
par(mar=c(2,0,0.5,1))
barplot(h2$counts, axes=FALSE, space=0, col='red', horiz=TRUE)
quantile(mus, probs = c(0.01 / 2, 1 - 0.01 / 2))
mu
quantile(tau2s, probs = c(0.01 / 2, 1 - 0.01 / 2))
tau2
median(tau2s)
median(mus)
hist(mus)
hist(tau2s)
hist(tau2s)
density(tau2s)
kd <- density(tau2s)
plot(kd)
kd <- density(mus)
kd
plot(tau2s, type = "l", main = "Trace plot of tau2", xlab = "Iteration", ylab = "tau2")
var(mus[100:mcmc_iters])
var(mus[100:mcmc_iters])
mus
mus[seq(100, 9000, 10)]
plot(mus[seq(100, 9000, 10)], type = "l")
var(mus[seq(100, 9000, 10)])
var(mus[100:mcmc_iters])
var(tau2s[seq(100, 9000, 10)])
var(tau2s[100:mcmc_iters])
dat
h1 <- hist(dat$mu, plot=FALSE)
h2 <- hist(dat$tau2, plot=FALSE)
top <- max(h1$counts, h2$counts)
k <- kde2d(dat$mu, dat$tau2, n = 100)
# margins
oldpar <- par()
par(mar=c(3,3,1,1))
layout(matrix(c(2,0,1,3),2,2, byrow=TRUE),c(3,1), c(1,3))
image(k, col=r) #plot the image
par(mar=c(0,2,1,0))
barplot(h1$counts, axes=FALSE, space=0, col='red')
par(mar=c(2,0,0.5,1))
barplot(h2$counts, axes=FALSE, space=0, col='red', horiz=TRUE)
dat
dat[,]
dat[,1]
mean(mus)
mean(mus)
median(mus)
quantile(tau2s, probs = c(0.01 / 2, 1 - 0.01 / 2))
quantile(tau2s, probs = c(0.05 / 2, 1 - 0.05 / 2))
dat
dat$tau2
1 / dat$tau2
hist(1 / dat$tau2)
hist(1 / dat$tau2)
mean(1 / dat$tau2)
median(1 / dat$tau2)
quantile(1 / tau2s, probs = c(0.05 / 2, 1 - 0.05 / 2))
quantile(1 / tau2s, probs = c(0.05 / 2, 1 - 0.05 / 2))
1 / dat$tau2
sqrt(dat$mu)
hist(sqrt(dat$mu))
setwd("/home/nurzhan/repos/caprecap_survey/_900_output/data/simulated/")
library(ggplot2)
dat <- read.csv("./estimates_0.5.csv")
summary(dat)
dat$T <- as.factor(dat$T)
ggplot(data = dat[dat$N == 1000,], mapping = aes(x = T, y = N_hat)) +
geom_boxplot() +
geom_hline(yintercept = 1000, linetype = "dashed", color = "red") +
labs(title = "Estimates of N with varying T",
x = "Number of time points (T)",
y = "Estimated population size (N_hat)") +
theme_minimal()
ggplot(data = dat[dat$N == 1000,], mapping = aes(x = T, y = N_hat)) +
geom_boxplot() +
geom_hline(yintercept = 1000, linetype = "dashed", color = "red") +
labs(title = "Estimates of N with varying T",
x = "Number of time points (T)",
y = "Estimated population size (N_hat)") +
scale_y_continuous(trans = 'log10') +
theme_minimal()
ggplot(data = dat[(dat$N == 1000)&(dat$type == "MPLE-NB"),], mapping = aes(x = T, y = N_hat)) +
geom_boxplot() +
geom_hline(yintercept = 1000, linetype = "dashed", color = "red") +
labs(title = "Estimates of N with varying T",
x = "Number of time points (T)",
y = "Estimated population size (N_hat)") +
scale_y_continuous(trans = 'log10') +
theme_minimal()
ggplot(data = dat[(dat$N == 1000)&(dat$type == "MPLE-G"),], mapping = aes(x = T, y = N_hat)) +
geom_boxplot() +
geom_hline(yintercept = 1000, linetype = "dashed", color = "red") +
labs(title = "Estimates of N with varying T",
x = "Number of time points (T)",
y = "Estimated population size (N_hat)") +
scale_y_continuous(trans = 'log10') +
theme_minimal()
ggplot(data = dat[(dat$N == 5000)&(dat$type == "MPLE-NB"),], mapping = aes(x = T, y = N_hat)) +
geom_boxplot() +
geom_hline(yintercept = 1000, linetype = "dashed", color = "red") +
labs(title = "Estimates of N with varying T",
x = "Number of time points (T)",
y = "Estimated population size (N_hat)") +
scale_y_continuous(trans = 'log10') +
theme_minimal()
ggplot(data = dat[(dat$N == 5000)&(dat$type == "MPLE-NB"),], mapping = aes(x = T, y = N_hat)) +
geom_boxplot() +
geom_hline(yintercept = 5000, linetype = "dashed", color = "red") +
labs(title = "Estimates of N with varying T",
x = "Number of time points (T)",
y = "Estimated population size (N_hat)") +
scale_y_continuous(trans = 'log10') +
theme_minimal()
ggplot(data = dat[(dat$N == 10000)&(dat$type == "MPLE-NB"),], mapping = aes(x = T, y = N_hat)) +
geom_boxplot() +
geom_hline(yintercept = 10000, linetype = "dashed", color = "red") +
labs(title = "Estimates of N with varying T",
x = "Number of time points (T)",
y = "Estimated population size (N_hat)") +
scale_y_continuous(trans = 'log10') +
theme_minimal()
ggplot(data = dat[(dat$N == 10000)&(dat$type == "MPLE-G"),], mapping = aes(x = T, y = N_hat)) +
geom_boxplot() +
geom_hline(yintercept = 10000, linetype = "dashed", color = "red") +
labs(title = "Estimates of N with varying T",
x = "Number of time points (T)",
y = "Estimated population size (N_hat)") +
scale_y_continuous(trans = 'log10') +
theme_minimal()
